Metadata-Version: 2.4
Name: rogchat
Version: 0.1.0
Summary: A RAG chatbot for the Humanoid AI book
Requires-Python: >=3.14
Description-Content-Type: text/markdown
Requires-Dist: requests>=2.31.0
Requires-Dist: trafilatura>=1.6.0
Requires-Dist: qdrant-client>=1.9.0
Requires-Dist: cohere>=5.0.0
Requires-Dist: xmltodict>=0.13.0

# RogChat - RAG Chatbot for Humanoid AI Book

A Retrieval-Augmented Generation (RAG) chatbot that allows users to ask questions about the Humanoid AI book content. The bot ingests documentation from a sitemap, stores it in a vector database, and retrieves relevant information to answer user queries.

## Features

- Sitemap-based content ingestion
- Text extraction from web pages
- Content chunking for optimal retrieval
- Vector storage using Qdrant
- Cohere-based embeddings for semantic search

## Installation

1. Install dependencies:
```bash
pip install requests trafilatura qdrant-client cohere xmltodict
```

Or using the pyproject.toml:
```bash
pip install -e .
```

## Configuration

The application uses the following configuration variables:

- `SITEMAP_URL`: URL of the sitemap to extract content from
- `COLLECTION_NAME`: Name of the Qdrant collection to store embeddings
- `COHERE_API_KEY`: Cohere API key for embeddings
- Qdrant Cloud credentials (URL and API key)

## Usage

### Ingestion

Run the main script to ingest the content:

```bash
python main.py
```

This will:
1. Extract URLs from the sitemap
2. Download and extract text from each page
3. Chunk the text into manageable pieces
4. Generate embeddings using Cohere
5. Store the embeddings in Qdrant

### Future: Chat Interface

A chat interface would be added to query the stored content.

## Architecture

1. **Content Extraction**: Downloads and extracts text from web pages using trafilatura
2. **Chunking**: Splits long documents into smaller chunks for better retrieval
3. **Embedding**: Converts text chunks to vector embeddings using Cohere
4. **Storage**: Stores embeddings in Qdrant vector database
5. **Retrieval**: Will retrieve relevant chunks based on user queries
